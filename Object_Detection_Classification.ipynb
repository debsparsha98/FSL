{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e35d2c-98b4-46eb-a3b1-4796973b810b",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1276\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1276\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1322\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1322\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1271\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1271\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1031\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1031\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m \n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:969\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1441\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1441\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:940\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    939\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m--> 940\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mIPPROTO_TCP, socket\u001b[38;5;241m.\u001b[39mTCP_NODELAY, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:824\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    823\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 824\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    825\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# -------------------\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# üîß Load YOLO-NAS Backbone\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# -------------------\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m backbone \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myolo_nas_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoco\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     29\u001b[0m backbone\u001b[38;5;241m.\u001b[39mhead \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mIdentity()  \u001b[38;5;66;03m# Remove detection head\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMAMLModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\super_gradients\\common\\decorators\\factory_decorator.py:36\u001b[0m, in \u001b[0;36mresolve_param.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m             new_value \u001b[38;5;241m=\u001b[39m factory\u001b[38;5;241m.\u001b[39mget(args[index])\n\u001b[0;32m     35\u001b[0m             args \u001b[38;5;241m=\u001b[39m _assign_tuple(args, index, new_value)\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\super_gradients\\training\\models\\model_factory.py:232\u001b[0m, in \u001b[0;36mget\u001b[1;34m(model_name, arch_params, num_classes, strict_load, checkpoint_path, pretrained_weights, load_backbone, download_required_code, checkpoint_num_classes, num_input_channels)\u001b[0m\n\u001b[0;32m    230\u001b[0m     net \u001b[38;5;241m=\u001b[39m instantiate_model(model_name, arch_params, checkpoint_num_classes, pretrained_weights, download_required_code)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     net \u001b[38;5;241m=\u001b[39m \u001b[43minstantiate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_required_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_backbone \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m checkpoint_path:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease set checkpoint_path when load_backbone=True\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\super_gradients\\training\\models\\model_factory.py:168\u001b[0m, in \u001b[0;36minstantiate_model\u001b[1;34m(model_name, arch_params, num_classes, pretrained_weights, download_required_code)\u001b[0m\n\u001b[0;32m    166\u001b[0m     load_pretrained_weights_local(net, model_name, pretrained_weights_path)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[43mload_pretrained_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrained_weights \u001b[38;5;129;01min\u001b[39;00m PRETRAINED_NUM_CLASSES\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;129;01mand\u001b[39;00m num_classes_new_head \u001b[38;5;241m!=\u001b[39m arch_params\u001b[38;5;241m.\u001b[39mnum_classes:\n\u001b[0;32m    171\u001b[0m     net\u001b[38;5;241m.\u001b[39mreplace_head(new_num_classes\u001b[38;5;241m=\u001b[39mnum_classes_new_head)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\super_gradients\\training\\utils\\checkpoint_utils.py:1595\u001b[0m, in \u001b[0;36mload_pretrained_weights\u001b[1;34m(model, architecture, pretrained_weights)\u001b[0m\n\u001b[0;32m   1593\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m wait_for_the_master(get_local_rank()):\n\u001b[1;32m-> 1595\u001b[0m         pretrained_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1597\u001b[0m _load_weights(architecture, model, pretrained_state_dict)\n\u001b[0;32m   1598\u001b[0m _maybe_load_preprocessing_params(model, pretrained_state_dict)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\hub.py:871\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[1;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[0;32m    869\u001b[0m         r \u001b[38;5;241m=\u001b[39m HASH_REGEX\u001b[38;5;241m.\u001b[39msearch(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[0;32m    870\u001b[0m         hash_prefix \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 871\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\hub.py:712\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[1;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[0;32m    710\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    711\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.hub\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m--> 712\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m meta \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(meta, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "# Object Classification\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from super_gradients.training import models\n",
    "from super_gradients.training.datasets.detection_datasets import YoloDarknetFormatDetectionDataset\n",
    "from super_gradients.training.transforms import DetectionTransform\n",
    "from super_gradients.training.metrics import DetectionMetrics\n",
    "'''from super_gradients.training.utils.detection_utils import DetectionCollateFN'''\n",
    "\n",
    "# -------------------\n",
    "# üîß CONFIGURATION\n",
    "# -------------------\n",
    "DATA_YAML = \"D:/data/data.yaml\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "N_WAY = 3\n",
    "K_SHOT = 5\n",
    "Q_QUERY = 10\n",
    "INNER_STEPS = 5\n",
    "INNER_LR = 1e-3\n",
    "META_LR = 1e-4\n",
    "EPOCHS = 10\n",
    "\n",
    "# -------------------\n",
    "# üîß Load YOLO-NAS Backbone\n",
    "# -------------------\n",
    "backbone = models.get('yolo_nas_s', pretrained_weights=\"coco\").to(DEVICE)\n",
    "backbone.head = nn.Identity()  # Remove detection head\n",
    "\n",
    "class MAMLModel(nn.Module):\n",
    "    def __init__(self, base_model, head_output=9):  # 9 classes in your dataset\n",
    "        super().__init__()\n",
    "        self.backbone = base_model\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1000, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, head_output)  # logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.head(features)\n",
    "\n",
    "# -------------------\n",
    "# üì¶ Custom Few-Shot Dataset Loader\n",
    "# -------------------\n",
    "def load_yolonas_dataset(split):\n",
    "    transform = DetectionTransform(image_size=416)\n",
    "    return YoloDarknetFormatDetectionDataset(\n",
    "        data_dir=\"D:/data\",\n",
    "        images_dir=os.path.join(\"images\", split),\n",
    "        labels_dir=os.path.join(\"labels\", split),\n",
    "        class_names=[\"airplane\", \"ship\", \"storage-tank\", \"ground-track-field\", \"harbor\", \"bridge\", \"large-vehicle\", \"small-vehicle\", \"helicopter\"],\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "train_dataset = load_yolonas_dataset(\"train\")\n",
    "val_dataset = load_yolonas_dataset(\"val\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=DetectionCollateFN(), num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=DetectionCollateFN(), num_workers=2)\n",
    "\n",
    "# -------------------\n",
    "# ‚öôÔ∏è MAML Meta-Training Loop\n",
    "# -------------------\n",
    "meta_model = MAMLModel(backbone).to(DEVICE)\n",
    "meta_optimizer = optim.Adam(meta_model.parameters(), lr=META_LR)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def clone_model(model):\n",
    "    import copy\n",
    "    return copy.deepcopy(model)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    meta_optimizer.zero_grad()\n",
    "    \n",
    "    meta_loss = 0.0\n",
    "    for task_idx in range(5):  # 5 tasks per meta-batch\n",
    "        learner = clone_model(meta_model)\n",
    "        learner.train()\n",
    "        support_set, query_set = [], []\n",
    "\n",
    "        for class_id in range(N_WAY):\n",
    "            class_samples = [sample for sample in train_dataset if sample['class'] == class_id]\n",
    "            support_set += class_samples[:K_SHOT]\n",
    "            query_set += class_samples[K_SHOT:K_SHOT + Q_QUERY]\n",
    "\n",
    "        # Inner-loop: Fine-tune learner\n",
    "        inner_optimizer = optim.SGD(learner.parameters(), lr=INNER_LR)\n",
    "        for _ in range(INNER_STEPS):\n",
    "            for sample in support_set:\n",
    "                img = sample['image'].unsqueeze(0).to(DEVICE)\n",
    "                label = torch.tensor([sample['class']]).to(DEVICE)\n",
    "                output = learner(img)\n",
    "                loss = loss_fn(output, label)\n",
    "                inner_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                inner_optimizer.step()\n",
    "\n",
    "        # Outer-loop: Query loss\n",
    "        for sample in query_set:\n",
    "            img = sample['image'].unsqueeze(0).to(DEVICE)\n",
    "            label = torch.tensor([sample['class']]).to(DEVICE)\n",
    "            output = learner(img)\n",
    "            meta_loss += loss_fn(output, label)\n",
    "\n",
    "    # Meta-optimizer step\n",
    "    meta_loss /= (N_WAY * Q_QUERY * 5)\n",
    "    meta_loss.backward()\n",
    "    meta_optimizer.step()\n",
    "    print(f\"Meta Loss: {meta_loss.item():.4f}\")\n",
    "\n",
    "# -------------------\n",
    "# ‚úÖ Validation / Test\n",
    "# -------------------\n",
    "meta_model.eval()\n",
    "correct = total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        images = batch['images'].to(DEVICE)\n",
    "        labels = batch['labels']\n",
    "        outputs = meta_model(images)\n",
    "        preds = outputs.argmax(dim=1).cpu()\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += len(labels)\n",
    "\n",
    "print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a5cd564-30c4-4f2a-b1af-e5bbbcc5ec0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DetectionCollateFN' from 'super_gradients.training.utils.detection_utils' (C:\\Users\\debsp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\super_gradients\\training\\utils\\detection_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuper_gradients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuper_gradients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YoloDarknetFormatDetectionDataset\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuper_gradients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DetectionCollateFN\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuper_gradients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YoloNASLoss\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DetectionCollateFN' from 'super_gradients.training.utils.detection_utils' (C:\\Users\\debsp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\super_gradients\\training\\utils\\detection_utils.py)"
     ]
    }
   ],
   "source": [
    "# Object Detection \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from super_gradients.training import models\n",
    "from super_gradients.training.datasets.detection_datasets import YoloDarknetFormatDetectionDataset\n",
    "from super_gradients.training.utils.detection_utils import DetectionCollateFN\n",
    "from super_gradients.training.losses import YoloNASLoss\n",
    "from copy import deepcopy\n",
    "\n",
    "# -------------------\n",
    "# üîß CONFIG\n",
    "# -------------------\n",
    "DATA_DIR = \"D:/data\"\n",
    "N_WAY = 3\n",
    "K_SHOT = 5\n",
    "Q_QUERY = 5\n",
    "INNER_LR = 1e-3\n",
    "META_LR = 1e-4\n",
    "INNER_STEPS = 5\n",
    "EPOCHS = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------\n",
    "# üì¶ Dataset Loader\n",
    "# -------------------\n",
    "def load_dataset(split):\n",
    "    return YoloDarknetFormatDetectionDataset(\n",
    "        data_dir=DATA_DIR,\n",
    "        images_dir=os.path.join(\"images\", split),\n",
    "        labels_dir=os.path.join(\"labels\", split),\n",
    "        class_names=[\n",
    "            \"airplane\", \"ship\", \"storage-tank\", \"ground-track-field\", \"harbor\",\n",
    "            \"bridge\", \"large-vehicle\", \"small-vehicle\", \"helicopter\"\n",
    "        ],\n",
    "    )\n",
    "\n",
    "train_dataset = load_dataset(\"train\")\n",
    "val_dataset = load_dataset(\"val\")\n",
    "\n",
    "# -------------------\n",
    "# üß† MAML Detector\n",
    "# -------------------\n",
    "class MAMLDetector(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.model = models.get('yolo_nas_s', pretrained_weights=\"coco\")\n",
    "        self.loss_fn = YoloNASLoss()\n",
    "        self.model.to(DEVICE)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_loss(self, preds, targets):\n",
    "        return self.loss_fn(preds, targets)\n",
    "\n",
    "    def clone(self):\n",
    "        return deepcopy(self)\n",
    "\n",
    "# -------------------\n",
    "# üîÅ Meta-Training Loop\n",
    "# -------------------\n",
    "meta_model = MAMLDetector().to(DEVICE)\n",
    "meta_optimizer = optim.Adam(meta_model.parameters(), lr=META_LR)\n",
    "\n",
    "def sample_task(dataset, n_way, k_shot, q_query):\n",
    "    class_to_samples = {}\n",
    "    for i, sample in enumerate(dataset):\n",
    "        for obj in sample['target']:\n",
    "            class_id = int(obj[-1])\n",
    "            class_to_samples.setdefault(class_id, []).append(sample)\n",
    "    \n",
    "    chosen_classes = random.sample(list(class_to_samples.keys()), n_way)\n",
    "    support, query = [], []\n",
    "    for c in chosen_classes:\n",
    "        samples = random.sample(class_to_samples[c], k_shot + q_query)\n",
    "        support.extend(samples[:k_shot])\n",
    "        query.extend(samples[k_shot:])\n",
    "    return support, query\n",
    "\n",
    "def prepare_batch(samples):\n",
    "    images = torch.stack([s['image'] for s in samples]).to(DEVICE)\n",
    "    targets = [s['target'].to(DEVICE) for s in samples]\n",
    "    return images, targets\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n[Epoch {epoch+1}]\")\n",
    "    meta_optimizer.zero_grad()\n",
    "    meta_loss = 0.0\n",
    "\n",
    "    for task_id in range(5):  # 5 tasks per meta-batch\n",
    "        learner = meta_model.clone()\n",
    "        inner_optimizer = optim.SGD(learner.parameters(), lr=INNER_LR)\n",
    "        \n",
    "        support_set, query_set = sample_task(train_dataset, N_WAY, K_SHOT, Q_QUERY)\n",
    "\n",
    "        # -----------------------\n",
    "        # üîÅ Inner Loop Training\n",
    "        # -----------------------\n",
    "        learner.train()\n",
    "        for _ in range(INNER_STEPS):\n",
    "            s_imgs, s_targets = prepare_batch(support_set)\n",
    "            s_preds = learner(s_imgs)\n",
    "            loss = learner.compute_loss(s_preds, s_targets)\n",
    "            inner_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            inner_optimizer.step()\n",
    "\n",
    "        # -----------------------\n",
    "        # üì§ Query Set Evaluation\n",
    "        # -----------------------\n",
    "        q_imgs, q_targets = prepare_batch(query_set)\n",
    "        q_preds = learner(q_imgs)\n",
    "        loss_q = learner.compute_loss(q_preds, q_targets)\n",
    "        meta_loss += loss_q\n",
    "\n",
    "    meta_loss /= 5\n",
    "    meta_loss.backward()\n",
    "    meta_optimizer.step()\n",
    "    print(f\"Meta Loss: {meta_loss.item():.4f}\")\n",
    "\n",
    "# -------------------\n",
    "# ‚úÖ Evaluation\n",
    "# -------------------\n",
    "from super_gradients.training.metrics.detection_metrics import DetectionMetrics\n",
    "\n",
    "meta_model.eval()\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=DetectionCollateFN())\n",
    "\n",
    "evaluator = DetectionMetrics(num_classes=9)\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        images = batch['images'].to(DEVICE)\n",
    "        targets = batch['targets']\n",
    "        preds = meta_model(images)\n",
    "        evaluator.update(preds, targets)\n",
    "\n",
    "map50 = evaluator.compute()['mAP_50']\n",
    "print(f\"\\nüìà mAP@50 on Validation Set: {map50:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4afd6242-947b-4ad4-b3a1-a24016429099",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'YoloNASLoss' from 'super_gradients.training.losses' (C:\\Users\\debsp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\super_gradients\\training\\losses\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuper_gradients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuper_gradients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YoloDarknetFormatDetectionDataset\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuper_gradients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YoloNASLoss\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuper_gradients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DetectionCollateFN\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuper_gradients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DetectionMetrics\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'YoloNASLoss' from 'super_gradients.training.losses' (C:\\Users\\debsp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\super_gradients\\training\\losses\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# MAML FSOD+Classification Code (YOLO-NAS)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "from super_gradients.training import models\n",
    "from super_gradients.training.datasets.detection_datasets import YoloDarknetFormatDetectionDataset\n",
    "from super_gradients.training.losses import YoloNASLoss\n",
    "from super_gradients.training.utils.detection_utils import DetectionCollateFN\n",
    "from super_gradients.training.metrics.detection_metrics import DetectionMetrics\n",
    "\n",
    "# -------------------\n",
    "# ‚öôÔ∏è Config\n",
    "# -------------------\n",
    "DATA_DIR = \"D:/data\"\n",
    "NUM_CLASSES = 9\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "N_WAY = 3\n",
    "K_SHOT = 5\n",
    "Q_QUERY = 5\n",
    "INNER_STEPS = 3\n",
    "INNER_LR = 1e-3\n",
    "META_LR = 1e-4\n",
    "EPOCHS = 10\n",
    "\n",
    "# -------------------\n",
    "# üì¶ Dataset Loader\n",
    "# -------------------\n",
    "def load_dataset(split):\n",
    "    return YoloDarknetFormatDetectionDataset(\n",
    "        data_dir=DATA_DIR,\n",
    "        images_dir=os.path.join(\"images\", split),\n",
    "        labels_dir=os.path.join(\"labels\", split),\n",
    "        class_names=[\n",
    "            \"airplane\", \"ship\", \"storage-tank\", \"ground-track-field\", \"harbor\",\n",
    "            \"bridge\", \"large-vehicle\", \"small-vehicle\", \"helicopter\"\n",
    "        ],\n",
    "    )\n",
    "\n",
    "train_dataset = load_dataset(\"train\")\n",
    "val_dataset = load_dataset(\"val\")\n",
    "\n",
    "# -------------------\n",
    "# üß† MAML-Compatible Detector\n",
    "# -------------------\n",
    "class MAMLDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.get(\"yolo_nas_s\", pretrained_weights=\"coco\")\n",
    "        self.loss_fn = YoloNASLoss()\n",
    "        self.model.to(DEVICE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_loss(self, preds, targets):\n",
    "        return self.loss_fn(preds, targets)\n",
    "\n",
    "    def clone(self):\n",
    "        return deepcopy(self)\n",
    "\n",
    "# -------------------\n",
    "# üéØ Few-Shot Task Sampling\n",
    "# -------------------\n",
    "def sample_task(dataset, n_way, k_shot, q_query):\n",
    "    class_to_samples = {}\n",
    "    for s in dataset:\n",
    "        for ann in s['target']:\n",
    "            class_id = int(ann[-1])\n",
    "            class_to_samples.setdefault(class_id, []).append(s)\n",
    "\n",
    "    chosen_classes = random.sample(list(class_to_samples.keys()), n_way)\n",
    "    support, query = [], []\n",
    "\n",
    "    for c in chosen_classes:\n",
    "        examples = random.sample(class_to_samples[c], k_shot + q_query)\n",
    "        support.extend(examples[:k_shot])\n",
    "        query.extend(examples[k_shot:])\n",
    "\n",
    "    return support, query\n",
    "\n",
    "def prepare_batch(samples):\n",
    "    images = torch.stack([s['image'] for s in samples]).to(DEVICE)\n",
    "    targets = [s['target'].to(DEVICE) for s in samples]\n",
    "    return images, targets\n",
    "\n",
    "# -------------------\n",
    "# üîÅ Meta-Learning Loop\n",
    "# -------------------\n",
    "meta_model = MAMLDetector().to(DEVICE)\n",
    "meta_optimizer = optim.Adam(meta_model.parameters(), lr=META_LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n[Epoch {epoch+1}]\")\n",
    "    meta_optimizer.zero_grad()\n",
    "    meta_loss = 0.0\n",
    "\n",
    "    for task in range(5):  # 5 tasks per meta-batch\n",
    "        learner = meta_model.clone()\n",
    "        inner_optimizer = optim.SGD(learner.parameters(), lr=INNER_LR)\n",
    "\n",
    "        support_set, query_set = sample_task(train_dataset, N_WAY, K_SHOT, Q_QUERY)\n",
    "\n",
    "        # ----------- Inner Loop -----------\n",
    "        learner.train()\n",
    "        for _ in range(INNER_STEPS):\n",
    "            s_imgs, s_targets = prepare_batch(support_set)\n",
    "            s_preds = learner(s_imgs)\n",
    "            s_loss = learner.compute_loss(s_preds, s_targets)\n",
    "            inner_optimizer.zero_grad()\n",
    "            s_loss.backward()\n",
    "            inner_optimizer.step()\n",
    "\n",
    "        # ----------- Outer Loop -----------\n",
    "        q_imgs, q_targets = prepare_batch(query_set)\n",
    "        q_preds = learner(q_imgs)\n",
    "        q_loss = learner.compute_loss(q_preds, q_targets)\n",
    "        meta_loss += q_loss\n",
    "\n",
    "    meta_loss /= 5\n",
    "    meta_loss.backward()\n",
    "    meta_optimizer.step()\n",
    "    print(f\"Meta Loss: {meta_loss.item():.4f}\")\n",
    "\n",
    "# -------------------\n",
    "# ‚úÖ Evaluation: Detection + Classification\n",
    "# -------------------\n",
    "meta_model.eval()\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=DetectionCollateFN())\n",
    "evaluator = DetectionMetrics(num_classes=NUM_CLASSES)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        images = batch['images'].to(DEVICE)\n",
    "        targets = batch['targets']\n",
    "        preds = meta_model(images)\n",
    "        evaluator.update(preds, targets)\n",
    "\n",
    "results = evaluator.compute()\n",
    "print(f\"\\nüìä Validation Results:\")\n",
    "print(f\"mAP@50: {results['mAP_50']:.4f}\")\n",
    "print(f\"mAP@50-95: {results['mAP_50_95']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53929869-8744-4223-8a38-b2e44a3ecd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import super_gradients\n",
    "    print(\"‚úÖ super_gradients is installed.\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå super_gradients is NOT installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a423e-d2fb-4cb4-88b2-4ecd112903a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "try:\n",
    "    urllib.request.urlopen(\"https://www.google.com\", timeout=5)\n",
    "    print(\"Internet access: OK\")\n",
    "except Exception as e:\n",
    "    print(f\"Internet access: FAIL ‚Äî {e}\")\n",
    "print (\"kell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc93ace-8b99-4285-9b88-4da827cfd3eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
